"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[6072],{3996:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>c,default:()=>m,frontMatter:()=>o,metadata:()=>l,toc:()=>h});var a=n(7462),r=(n(7294),n(3905)),s=n(4866),i=n(5162);n(5739);const o={sidebar_position:3,slug:"/caching",label:"Caching"},c="Caching",l={unversionedId:"caching",id:"caching",title:"Caching",description:"This page describes the guiding principles of the Skyline caching approach.",source:"@site/docs/caching.md",sourceDirName:".",slug:"/caching",permalink:"/docs/caching",draft:!1,tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3,slug:"/caching",label:"Caching"},sidebar:"tutorialSidebar",previous:{title:"Environment",permalink:"/docs/environment"},next:{title:"CLI",permalink:"/docs/cli"}},d={},h=[{value:"Introduction",id:"introduction",level:2},{value:"Caching strategy overview",id:"caching-strategy-overview",level:2},{value:"Code example walkthrough",id:"code-example-walkthrough",level:2}],u={toc:h},p="wrapper";function m(e){let{components:t,...n}=e;return(0,r.kt)(p,(0,a.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"caching"},"Caching"),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"This page describes the guiding principles of the Skyline caching approach. ",(0,r.kt)("br",null),"\nThe API reference of the ",(0,r.kt)("inlineCode",{parentName:"p"},"@skyline-js/cache")," package can be found here: ",(0,r.kt)("a",{parentName:"p",href:"/docs/api-reference/cache"},"@skyline-js/cache"))),(0,r.kt)("h2",{id:"introduction"},"Introduction"),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"There are only two hard things in Computer Science: cache invalidation and managing your package.json.")),(0,r.kt)("p",null,"Good news, we are about to solve cache invalidation. Regarding your package-lock.json merge conflicts, we send our prayers and thoughts. But why is caching so difficult? Consider this simple scenario of two servers, a database and a cache:"),(0,r.kt)("br",null),(0,r.kt)("mermaid",{value:"%%{init:{'themeCSS':' .noteText { tspan { fill: white; } }; .note { fill: darkred };'}}%%\n\nsequenceDiagram\n    autonumber\n\n    participant Server 1\n    participant Cache\n    participant Server 2\n\n    Server 1->> Cache: Get user:1\n    Cache ->> Server 1: Cache miss\n    Server 1->> Server 1: Get user:1 from database\n\n    Server 2->> Server 2: Update user:1 in database\n    Server 2 ->> Cache: Write udpated user:1\n\n    Server 1 ->> Cache: Write old user:1\n\n    Note over Server 1,Server 2: Cache is inconsistent\n\n"}),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"Note: the diagram does not show the database as a separate column due to space constraints.")),(0,r.kt)("br",null),(0,r.kt)("p",null,"Server 1 wants to read ",(0,r.kt)("inlineCode",{parentName:"p"},"user:1")," from the cache. As the user is not cached yet, he has to fetch the user from the database. To have the user cached for the next read operation, Server 1 writes the user to the cache. In the meantime, Server 2 updates the name of ",(0,r.kt)("inlineCode",{parentName:"p"},"user:1"),". He then proceeds to write the updated user to the cache."),(0,r.kt)("p",null,"The diagram shows how an unfortunate timing of these operations can result in an inconsistent cache. Timing dependent bugs are hard to observe and reproduce and are therfore well suited to destroy the morale and sanity of one or more developers."),(0,r.kt)("p",null,"How can we protect ourselves against this scenario? A solution could be to only write to the cache if no value exists for the key. This would prevent the write operation from Server 1 to write an old value for ",(0,r.kt)("inlineCode",{parentName:"p"},"user:1")," to the cache. However, what if the write operation of Server 1 is faster than the write operation of Server 2? In this case, a value for ",(0,r.kt)("inlineCode",{parentName:"p"},"user:1")," would alreay exist in the cache and therefore the write operation of Server 2 would be discarded, producing an inconsistent cache again."),(0,r.kt)("p",null,"To solve this problem, we could always write to the cache after we perform an update operation, regardless of whether a value exists in the cache or not. Sounds good, but this just produces more problems. Consider this diagram where two servers update the same user in parallel:"),(0,r.kt)("mermaid",{value:"%%{init:{'themeCSS':'.note { fill: darkred }; .noteText { tspan { fill: white; } } '}}%%\nsequenceDiagram\n    autonumber\n\n    participant Server 1\n    participant Cache\n    participant Server 2\n\n    Server 1 ->> Server 1: Update user:1 in database\n    Server 2 ->> Server 2: Update user:1 in database\n    Server 2 ->> Cache: Write udpated user:1\n    Server 1 ->> Cache: Write udpated user:1\n\n    Note over Server 1,Server 2: Cache is inconsistent"}),(0,r.kt)("br",null),(0,r.kt)("p",null,"I hope that this short thought experiment clearly demonstrates the need for a caching strategy that provides consistency regardless of the order of operations that are executed on the cache. This garantuee cannot come at the expense of the complexity of the code that needs to be written, because complex code is hard to write and even harder to test, so it will be buggy and therefore not provide a garantuee."),(0,r.kt)("p",null,"Enter the Skyline caching framework, that solves all of these problems while still providing a simple interface to the developer - by borrowing a trick or two from theoretical computer science."),(0,r.kt)("h2",{id:"caching-strategy-overview"},"Caching strategy overview"),(0,r.kt)("p",null,"The skyline caching strategy is based on the following rules:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Writing a value to a cache key only happens if the cache key is not set yet."),(0,r.kt)("li",{parentName:"ol"},"Writing a value to a cache key only happens if the value is not stale."),(0,r.kt)("li",{parentName:"ol"},'Invalidating a cache key sets the value to "blocked" for a certain amount of time.'),(0,r.kt)("li",{parentName:"ol"},"A value retrieved for a cache key has to be validated regarding its structure.")),(0,r.kt)("p",null,"Following these rules, no cache inconsistencies can occurr due to timing issues. However, the cache invalidation itself still needs to be done by the developer whenever a value changes. As this is very easy to forget, we furthermore need a process in place to deal with cache inconsistencies due to missing invalidations:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Every cache read has a probability of being skipped, which is resulting in a forced cache miss. This probability should be set to 100% for a newly introduced cache."),(0,r.kt)("li",{parentName:"ol"},"A skipped cache read results in the fetching of the value from the source of truth, followed by writing the value to the cache. The write operation fetches the cached value and compares it to the value that was fetched from the source of truth to detect an inconsistency."),(0,r.kt)("li",{parentName:"ol"},"The skip probability can be reduced with increasing confidence in the feature. However, in local development, CI and testing environments it should always be 100% to catch any inconsistencies that have been (re)introduced.")),(0,r.kt)("p",null,"Finally, we need a strategy for minimizing the impact that a caching error has on our production system:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Caching has to be optional to the correct functioning of the application. If the cache throws an error, it will be identical to a cache miss for the application. Errors are always logged but catched in production - in local development, CI and testing environments always thrown."),(0,r.kt)("li",{parentName:"ol"},"A cache key consists of a namespace (e.g., ",(0,r.kt)("inlineCode",{parentName:"li"},"user"),") and a key (e.g., ",(0,r.kt)("inlineCode",{parentName:"li"},"1"),"). If a cache inconsistency is detected, the entire namespace is disabled as the inconsistency is likely due to a systematic problem with that namespace's invalidation instead of only the individual key being affected.")),(0,r.kt)("br",null),(0,r.kt)("p",null,"Let's revisit the initial diagram with these rules in mind:"),(0,r.kt)("mermaid",{value:"%%{init:{'themeCSS':'.note { fill: darkgreen }; .noteText { tspan { fill: white; } } '}}%%\n\n\nsequenceDiagram\n    autonumber\n\n    participant Server 1\n    participant Cache\n    participant Server 2\n\n    Server 1->> Cache: Get user:1\n    Cache ->> Server 1: Cache miss\n    Server 1->> Server 1: Get user:1 from database\n\n    Server 2 ->> Server 2: Update user:1 in database\n    Server 2 ->> Cache: Invalidate user:1\n\n    Server 1 --\x3e> Cache: Write old user:1\n\n    Note over Server 1,Server 2: Cache is consistent\n"}),(0,r.kt)("br",null),(0,r.kt)("p",null,"Why is the cache now consistent? Step 1 - 4 are identical, however Step 5 invalidates the cache ",(0,r.kt)("inlineCode",{parentName:"p"},"user:1"),", which sets the value of the key to ",(0,r.kt)("inlineCode",{parentName:"p"},"blocked")," for a certain amount of time (e.g., 1 second). This causes the cache write of the old value in Step 6 to be discarded."),(0,r.kt)("p",null,"You could argue: ",(0,r.kt)("em",{parentName:"p"},'"What if the time between Step 5 and Step 6 is longer than 1 second? In this case, the old value would still be written to the cache!"'),"."),(0,r.kt)("p",null,"This would be correct without the staleness check rule. A value is stale and will therefore be discarded when writing it to the cache if it has been fetched from the source of truth longer than a certain threshold amount of time (e.g., 1 second). In this scenario, the ",(0,r.kt)("inlineCode",{parentName:"p"},"fetchedAt")," timestamp is recorded on Step 3, before the database is queried for the user. If the time between Step 5 and Step 6 is below 1 second, the write will be discarded because the cache key still exists (with the ",(0,r.kt)("inlineCode",{parentName:"p"},"blocked")," value). If the time is above 1 second, the write will be discarded because the value has passed the stale threshold."),(0,r.kt)("p",null,"The cache inconsistencies are mitigated, let's see if the happy path of this diagram is still fullfilled: If Step 4 and 5 do not happen, the cache key ",(0,r.kt)("inlineCode",{parentName:"p"},"user:1")," never gets blocked and therefore the correct value for ",(0,r.kt)("inlineCode",{parentName:"p"},"user:1")," is written to the cache in Step 6. Nice!"),(0,r.kt)("br",null),(0,r.kt)("p",null,"Let's look at the second diagram:"),(0,r.kt)("mermaid",{value:"%%{init:{'themeCSS':'.note { fill: darkgreen }; .noteText { tspan { fill: white; } } '}}%%\nsequenceDiagram\n    autonumber\n\n    participant Server 1\n    participant Cache\n    participant Server 2\n\n    Server 1 ->> Server 1: Update user:1 in database\n    Server 2 ->> Server 2: Update user:1 in database\n    Server 2 ->> Cache: Invalidate user:1\n    Server 1 ->> Cache: Invalidate user:1\n\n    Note over Server 1,Server 2: Cache is inconsistent"}),(0,r.kt)("br",null),(0,r.kt)("p",null,"This one is easy. The cache just gets invalidated twice, so it is obviously not inconsistent. However, an important detail here is that the second invalidation has to reset the TTL (time-to-live) of the ",(0,r.kt)("inlineCode",{parentName:"p"},"blocked")," value for ",(0,r.kt)("inlineCode",{parentName:"p"},"user:1")," to its configured value, otherwise the cache key's ",(0,r.kt)("inlineCode",{parentName:"p"},"blocked")," value could expire to soon and a late write operation as depicted in the first diagram could mess up our cache afterall."),(0,r.kt)("p",null,"To summarize, we leverage the asymmetry of a cache key being read (a lot) and a cache key being invalidated (not so often) by blocking a cache key for some time on invalidation. While we loose using the cache during this time, we gain the garantuee of a consistent cache for the rest of cache value's lifetime. Quite a bargain if you ask me! If a cache key gets invalidated frequently, we would not be able to use the cache. However, in this case caching might be the wrong approach anyways as caching is most useful for values that do not change too often."),(0,r.kt)("h2",{id:"code-example-walkthrough"},"Code example walkthrough"),(0,r.kt)("p",null,"I will demonstrate the Skyline caching strategy based on the following scenario: Yout want to build a NestJS web application server that stores its data in a relational database and uses Redis for caching. Your application has a dedicated data-access layer, which abstracts away the communication with the database. This is done via repositories, which offer methods to perform SQL operations on a specific database table (or multiple depending on the use-case). The database schema and therefore the SQL query structure is hidden from the consumer of the repository. The repository implements a read-through caching strategy:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Retrieve the requested value from the cache."),(0,r.kt)("li",{parentName:"ol"},"If the value could be retrieved from the cache, return it."),(0,r.kt)("li",{parentName:"ol"},"If the value is not present, retrieve the value from the database, write it to the cache and then return it.")),(0,r.kt)("p",null,"We start with such a repository for the ",(0,r.kt)("inlineCode",{parentName:"p"},"user")," entity:"),(0,r.kt)(s.Z,{path:"apps/cache-example-nestjs-minimal/src/app/",order:"user.repository.ts, user.entity.ts, user.interface.ts, user.utils.ts, user.controller.ts, database-cache.service.ts",mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"user.repository",label:"user.repository.ts",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-ts"},"import { Injectable } from '@nestjs/common';\nimport { InjectDataSource } from '@nestjs/typeorm';\nimport { DataSource, EntityNotFoundError } from 'typeorm';\nimport { DatabaseCacheService } from './database-cache.service';\nimport { UserEntity } from './user.entity';\nimport {\n  CreateUserInputValobj,\n  UpdateUserInputValobj,\n  UserValobj,\n} from './user.interface';\nimport { isUserRowOrThrow, isUserRowsOrThrow } from './user.utils';\n\n@Injectable()\nexport class UserRepository {\n  constructor(\n    private readonly cache: DatabaseCacheService,\n    @InjectDataSource() private readonly dataSource: DataSource\n  ) {}\n\n  async getUsersByIds(\n    userIds: number[]\n  ): Promise<Array<UserValobj | undefined>> {\n    if (!userIds.length) return [];\n\n    // Check cache\n    const { values: cachedUserRows, skipped } = await this.cache.getMany(\n      'user',\n      userIds,\n      isUserRowOrThrow,\n      { skip: 0.5 }\n    );\n\n    const missingUserIds = userIds.filter(\n      (userId) => !cachedUserRows.some((row) => row?.id === userId)\n    );\n\n    // Query database for missing userIds\n    let missingRows: UserValobj[] = [];\n    if (missingUserIds.length > 0) {\n      const fetchedAt = Date.now();\n      missingRows = await this.dataSource\n        .createQueryBuilder(UserEntity, 'user')\n        .select('*')\n        .whereInIds(missingUserIds)\n        .execute();\n\n      isUserRowsOrThrow(missingRows);\n\n      // Cache missing rows\n      await this.cache.setManyIfNotExist('user', (row) => row.id, missingRows, {\n        fetchedAt,\n        validate: skipped,\n      });\n    }\n\n    const rows = [...cachedUserRows, ...missingRows];\n    return userIds.map((userId) => rows.find((user) => user?.id === userId));\n  }\n\n  async getUsersById(userId: number): Promise<UserValobj | undefined> {\n    const [user] = await this.getUsersByIds([userId]);\n    return user;\n  }\n\n  async getUsersByIdOrFail(userId: number): Promise<UserValobj> {\n    const user = await this.getUsersById(userId);\n    if (!user)\n      throw new EntityNotFoundError(\n        UserEntity,\n        `User with ID ${userId} not found`\n      );\n\n    return user;\n  }\n\n  async createUser(input: CreateUserInputValobj) {\n    const rows =\n      (\n        await this.dataSource\n          .createQueryBuilder()\n          .insert()\n          .into(UserEntity)\n          .values(input)\n          .returning('*')\n          .execute()\n      ).raw ?? [];\n\n    isUserRowsOrThrow(rows);\n    const user = rows[0];\n    return user;\n  }\n\n  async updateUser(input: UpdateUserInputValobj) {\n    // Invalidate cache\n    await this.cache.invalidate('user', input.id);\n\n    const rows =\n      (\n        await this.dataSource\n          .createQueryBuilder()\n          .update(UserEntity)\n          .set(input)\n          .where('id = :id', { id: input.id })\n          .returning('*')\n          .execute()\n      ).raw ?? [];\n\n    isUserRowsOrThrow(rows);\n    const user = rows[0];\n    return user;\n  }\n\n  async deleteUser(userId: number) {\n    // Invalidate cache\n    await this.cache.invalidate('user', userId);\n\n    await this.dataSource\n      .createQueryBuilder()\n      .delete()\n      .from(UserEntity)\n      .where('id = :id', { id: userId })\n      .execute();\n  }\n}\n"))),(0,r.kt)(i.Z,{value:"user.entity",label:"user.entity.ts",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-ts"},"import { Column, Entity, PrimaryGeneratedColumn } from 'typeorm';\n\n@Entity()\nexport class UserEntity {\n  @PrimaryGeneratedColumn({ type: 'integer' })\n  id!: number;\n\n  @Column({ type: 'varchar', length: 255, nullable: false })\n  name!: string;\n}\n"))),(0,r.kt)(i.Z,{value:"user.interface",label:"user.interface.ts",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-ts"},"export interface UserValobj {\n  id: number;\n  name: string;\n}\n\nexport interface CreateUserInputValobj {\n  name: string;\n}\n\nexport interface UpdateUserInputValobj {\n  id: number;\n  name: string;\n}\n"))),(0,r.kt)(i.Z,{value:"user.utils",label:"user.utils.ts",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-ts"},"import { UserValobj } from './user.interface';\n\nexport function isUserRowsOrThrow(\n  candidates: unknown[]\n): asserts candidates is UserValobj[] {\n  if (!Array.isArray(candidates)) {\n    throw new Error(`Expected array, got ${typeof candidates}`);\n  }\n\n  for (const candidate of candidates) {\n    if (typeof candidate !== 'object' || candidate === null) {\n      throw new Error(`Expected object, got ${typeof candidate}`);\n    }\n\n    if (typeof (candidate as UserValobj).id !== 'number') {\n      throw new Error(\n        `Expected number, got ${typeof (candidate as UserValobj).id}`\n      );\n    }\n\n    if (typeof (candidate as UserValobj).name !== 'string') {\n      throw new Error(\n        `Expected string, got ${typeof (candidate as UserValobj).name}`\n      );\n    }\n  }\n}\n\nexport function isUserRowOrThrow(\n  candidate: unknown\n): asserts candidate is UserValobj {\n  isUserRowsOrThrow([candidate]);\n}\n"))),(0,r.kt)(i.Z,{value:"user.controller",label:"user.controller.ts",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-ts"},"import { Body, Controller, Delete, Get, Param, Post } from '@nestjs/common';\nimport { UserRepository } from './user.repository';\n\n@Controller()\nexport class UserController {\n  constructor(private readonly userRepo: UserRepository) {}\n\n  @Get('user/:id')\n  async getUserById(@Param() params: { id: number }) {\n    const id = Number(params.id);\n    const user = await this.userRepo.getUsersById(id);\n    return { user };\n  }\n\n  @Get('users/:ids')\n  async getUsersByIds(@Param() params: { ids: string }) {\n    const ids = params.ids.split(',').map(Number);\n    const users = await this.userRepo.getUsersByIds(ids);\n    return { users };\n  }\n\n  @Post('user')\n  async createUser(@Body() input: { name: string }) {\n    const user = await this.userRepo.createUser({ name: input.name });\n    return { user };\n  }\n\n  @Delete('user/:id')\n  async deleteUser(@Param() params: { id: number }) {\n    const id = Number(params.id);\n    await this.userRepo.deleteUser(id);\n    return { id };\n  }\n}\n"))),(0,r.kt)(i.Z,{value:"database-cache.service",label:"database-cache.service.ts",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-ts"},"import { Injectable } from '@nestjs/common';\nimport { RedisCacheStorageEngine, SkylineCache } from '@skylinejs/cache';\nimport { createClient } from 'redis';\n\n@Injectable()\nexport class DatabaseCacheService extends SkylineCache {\n  constructor() {\n    const redis = createClient({ url: 'redis://skyline_redis:6379' });\n    redis.connect();\n\n    super({\n      storage: new RedisCacheStorageEngine({\n        redis,\n      }),\n      config: {},\n    });\n  }\n}\n"))),(0,r.kt)(i.Z,{value:"app.module",label:"app.module.ts",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-ts"},"import { Module } from '@nestjs/common';\nimport { UserController } from './user.controller';\nimport { UserRepository } from './user.repository';\nimport { TypeOrmModule } from '@nestjs/typeorm';\nimport { UserEntity } from './user.entity';\nimport { DatabaseCacheService } from './database-cache.service';\n\n@Module({\n  imports: [\n    TypeOrmModule.forRoot({\n      type: 'postgres',\n      url: 'postgres://postgres:postgres@skyline_postgres:5432/postgres',\n      schema: 'public',\n      dropSchema: true,\n      synchronize: true,\n      entities: [UserEntity],\n    }),\n  ],\n  controllers: [UserController],\n  providers: [DatabaseCacheService, UserRepository],\n})\nexport class AppModule {}\n")))),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"getUsersByIds")," retrieves one or more users by their ID. This method should be the basic building block for most of your repositories, as many other methods such as ",(0,r.kt)("inlineCode",{parentName:"p"},"getUserById"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"getUserByIdOrFail")," etc. can be derived from it (and you are not tempted to implement a ",(0,r.kt)("inlineCode",{parentName:"p"},"Promise.all()")," if you need to get multiple entities by ID later on...)."),(0,r.kt)("p",null,"Due to the batched API of the method, we need to adjust the read-through caching execution flow as follows:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Retrieve the values for all input IDs from the cache."),(0,r.kt)("li",{parentName:"ol"},"If some values are missing, retrieve the missing values from the database and write them to the cache."),(0,r.kt)("li",{parentName:"ol"},"For each input ID, return either the retrieved value or ",(0,r.kt)("inlineCode",{parentName:"li"},"undefined")," if the ID does not exist.")),(0,r.kt)("p",null,"This is the only read/write interaction with the cache that this repository has to implement, as all other read operations are derived from ",(0,r.kt)("inlineCode",{parentName:"p"},"getUsersByIds"),". This part was easy, and the remaining cache interactions get even easier."),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"updateUser")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"deleteUser")," methods simply need to invalidate the cache key for the given user ID ",(0,r.kt)("strong",{parentName:"p"},"before")," the update/ deletion is performed on the database row. If the cache is invalidated after the database operation has finished, the cache would be in an inconsistent state as it still holds the old user value which now diverges from the database row. If other repositories change make changes to the user table, they need to invalidate the respective cache keys as well. One of the main advantages of the invalidation approach instead of writing the updated value to the cache is that the method performing the update of the entity does not need to know how all the new values of the affected cache keys have to look like (which can be complex derivations or aggregates). This turns out to be very useful for larger applications."))}m.isMDXComponent=!0}}]);